{
  "openai-o3-pro": {
    "key": "openai-o3-pro",
    "name": "o3-pro",
    "modelString": "o3-pro",
    "providerKey": "openai",
    "description": "Most capable reasoning model, designed for challenging questions where reliability is prioritized",
    "contextWindow": 200000,
    "outputWindow": 200000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "tools", "json", "multimodal", "extended-thinking", "agentic"],
    "supportedModes": ["streaming", "json", "tools"],
    "costPer1kTokens": {
      "input": 20.0,
      "output": 80.0
    },
    "latencyClass": "slow",
    "status": "active"
  },
  "openai-o3": {
    "key": "openai-o3",
    "name": "o3",
    "modelString": "o3",
    "providerKey": "openai",
    "description": "Advanced reasoning model with agentic tool use and multi-step problem solving",
    "contextWindow": 200000,
    "outputWindow": 200000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "tools", "json", "multimodal", "extended-thinking", "agentic"],
    "supportedModes": ["streaming", "json", "tools"],
    "costPer1kTokens": {
      "input": 10.0,
      "output": 40.0
    },
    "latencyClass": "standard",
    "status": "active"
  },
  "openai-o4-mini": {
    "key": "openai-o4-mini",
    "name": "o4-mini",
    "modelString": "o4-mini",
    "providerKey": "openai",
    "description": "Fast, cost-efficient reasoning model excelling at math, coding, and visual tasks",
    "contextWindow": 200000,
    "outputWindow": 200000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "tools", "json", "multimodal", "extended-thinking"],
    "supportedModes": ["streaming", "json", "tools"],
    "costPer1kTokens": {
      "input": 1.1,
      "output": 4.4
    },
    "latencyClass": "fast",
    "status": "active"
  },
  "openai-o3-mini": {
    "key": "openai-o3-mini",
    "name": "o3-mini",
    "modelString": "o3-mini",
    "providerKey": "openai",
    "description": "Cost-efficient reasoning model optimized for coding, math, and science",
    "contextWindow": 200000,
    "outputWindow": 200000,
    "knowledgeCutoff": "2023-10",
    "capabilities": ["chat", "completion", "tools", "json", "extended-thinking"],
    "supportedModes": ["streaming", "json", "tools"],
    "costPer1kTokens": {
      "input": 1.1,
      "output": 4.4
    },
    "latencyClass": "fast",
    "status": "active",
    "limitations": ["no-image-input"]
  },
  "openai-gpt-4.1": {
    "key": "openai-gpt-4.1",
    "name": "GPT-4.1",
    "modelString": "gpt-4.1",
    "providerKey": "openai",
    "description": "Flagship GPT model with 1M context, improved coding and instruction following",
    "contextWindow": 1000000,
    "outputWindow": 128000,
    "knowledgeCutoff": "2024-05",
    "isDefault": true,
    "capabilities": ["chat", "completion", "tools", "json", "image-input"],
    "supportedModes": ["streaming", "json", "tools"],
    "costPer1kTokens": {
      "input": 2.0,
      "output": 8.0
    },
    "latencyClass": "standard",
    "status": "active",
    "limitations": ["image-input-only"]
  },
  "openai-gpt-4.5": {
    "key": "openai-gpt-4.5",
    "name": "GPT-4.5",
    "modelString": "gpt-4.5",
    "providerKey": "openai",
    "description": "Advanced general-purpose model with full multimodal capabilities",
    "contextWindow": 128000,
    "outputWindow": 128000,
    "knowledgeCutoff": "2023-10",
    "capabilities": ["chat", "completion", "tools", "json", "multimodal"],
    "supportedModes": ["streaming", "json", "tools"],
    "costPer1kTokens": {
      "input": 10.0,
      "output": 40.0
    },
    "latencyClass": "standard",
    "status": "beta"
  },
  "anthropic-claude-4-opus": {
    "key": "anthropic-claude-4-opus",
    "name": "Claude 4 Opus",
    "modelString": "claude-4-opus-20250514",
    "providerKey": "anthropic",
    "description": "Most powerful Claude model with hybrid reasoning for long-running agentic tasks",
    "contextWindow": 200000,
    "outputWindow": 4096,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "tools", "json", "multimodal", "hybrid-thinking", "agentic"],
    "supportedModes": ["streaming", "json", "tools"],
    "costPer1kTokens": {
      "input": 15.0,
      "output": 75.0
    },
    "latencyClass": "standard",
    "status": "active"
  },
  "anthropic-claude-4-sonnet": {
    "key": "anthropic-claude-4-sonnet",
    "name": "Claude 4 Sonnet",
    "modelString": "claude-4-sonnet-20250514",
    "providerKey": "anthropic",
    "description": "Balanced Claude model with hybrid thinking and extended tool use",
    "contextWindow": 200000,
    "outputWindow": 4096,
    "knowledgeCutoff": "2024-05",
    "isDefault": true,
    "capabilities": ["chat", "completion", "tools", "json", "multimodal", "hybrid-thinking"],
    "supportedModes": ["streaming", "json", "tools"],
    "latencyClass": "standard",
    "status": "active"
  },
  "anthropic-claude-3.7-sonnet": {
    "key": "anthropic-claude-3.7-sonnet",
    "name": "Claude 3.7 Sonnet",
    "modelString": "claude-3.7-sonnet",
    "providerKey": "anthropic",
    "description": "Enhanced reasoning with large context window and improved accuracy",
    "contextWindow": 200000,
    "outputWindow": 4096,
    "knowledgeCutoff": "2025-02",
    "capabilities": ["chat", "completion", "tools", "json", "multimodal"],
    "supportedModes": ["streaming", "json", "tools"],
    "latencyClass": "fast",
    "status": "active"
  },
  "google-gemini-2.5-pro": {
    "key": "google-gemini-2.5-pro",
    "name": "Gemini 2.5 Pro",
    "modelString": "gemini-2.5-pro-preview-06-05",
    "providerKey": "google",
    "description": "Most intelligent Gemini model with Deep Think mode and 1M context",
    "contextWindow": 1000000,
    "outputWindow": 8192,
    "knowledgeCutoff": "2025-01",
    "isDefault": true,
    "capabilities": ["chat", "completion", "multimodal", "deep-think", "tools", "native-audio"],
    "supportedModes": ["streaming", "json"],
    "costPer1kTokens": {
      "input": 1.875,
      "output": 12.5
    },
    "latencyClass": "standard",
    "status": "active"
  },
  "google-gemini-2.5-flash": {
    "key": "google-gemini-2.5-flash",
    "name": "Gemini 2.5 Flash",
    "modelString": "gemini-2.5-flash",
    "providerKey": "google",
    "description": "Fast, efficient model with 1M context and configurable thinking",
    "contextWindow": 1000000,
    "outputWindow": 8192,
    "knowledgeCutoff": "2025-01",
    "capabilities": ["chat", "completion", "multimodal", "configurable-thinking", "native-audio"],
    "supportedModes": ["streaming", "json"],
    "costPer1kTokens": {
      "input": 0.3,
      "output": 2.5
    },
    "latencyClass": "fast",
    "status": "active"
  },
  "google-gemini-2.5-flash-lite": {
    "key": "google-gemini-2.5-flash-lite",
    "name": "Gemini 2.5 Flash-Lite",
    "modelString": "gemini-2.5-flash-lite",
    "providerKey": "google",
    "description": "Most cost-efficient Gemini with lowest latency and thinking control",
    "contextWindow": 1000000,
    "outputWindow": 8192,
    "knowledgeCutoff": "2024-06",
    "capabilities": ["chat", "completion", "multimodal", "thinking-control"],
    "supportedModes": ["streaming", "json"],
    "costPer1kTokens": {
      "input": 0.1,
      "output": 0.4
    },
    "latencyClass": "fast",
    "status": "beta"
  },
  "google-gemini-2.0-pro": {
    "key": "google-gemini-2.0-pro",
    "name": "Gemini 2.0 Pro",
    "modelString": "gemini-2.0-pro",
    "providerKey": "google",
    "description": "Variable context multimodal model with advanced tool use",
    "contextWindow": 2000000,
    "outputWindow": 8192,
    "knowledgeCutoff": "2025-01",
    "capabilities": ["chat", "completion", "multimodal", "real-time-web", "code-execution"],
    "supportedModes": ["streaming", "json"],
    "latencyClass": "standard",
    "status": "active"
  },
  "perplexity-sonar-pro": {
    "key": "perplexity-sonar-pro",
    "name": "Sonar Pro",
    "modelString": "sonar-pro",
    "providerKey": "perplexity",
    "description": "Advanced web search model with comprehensive citations and multi-step research",
    "contextWindow": 200000,
    "outputWindow": 8000,
    "knowledgeCutoff": "2024-05",
    "isDefault": true,
    "capabilities": ["chat", "completion", "web-search", "citations", "multimodal", "deep-research"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 2.0,
      "output": 4.0
    },
    "latencyClass": "standard",
    "status": "active",
    "features": ["real-time-web", "source-citations"]
  },
  "perplexity-sonar-reasoning-pro": {
    "key": "perplexity-sonar-reasoning-pro",
    "name": "Sonar Reasoning Pro",
    "modelString": "sonar-reasoning-pro",
    "providerKey": "perplexity",
    "description": "Chain-of-thought reasoning with web search and structured outputs",
    "contextWindow": 128000,
    "outputWindow": 8000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "web-search", "citations", "multimodal", "chain-of-thought"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 2.0,
      "output": 4.0
    },
    "latencyClass": "standard",
    "status": "active"
  },
  "perplexity-sonar-reasoning": {
    "key": "perplexity-sonar-reasoning",
    "name": "Sonar Reasoning",
    "modelString": "sonar-reasoning",
    "providerKey": "perplexity",
    "description": "Chain-of-thought reasoning with web search",
    "contextWindow": 128000,
    "outputWindow": 8000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "web-search", "citations", "multimodal", "chain-of-thought"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 2.0,
      "output": 4.0
    },
    "latencyClass": "standard",
    "status": "active"
  },
  "perplexity-sonar": {
    "key": "perplexity-sonar",
    "name": "Sonar",
    "modelString": "sonar",
    "providerKey": "perplexity",
    "description": "Fast web search model with citations for everyday factual Q&A",
    "contextWindow": 128000,
    "outputWindow": 8000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "web-search", "citations", "multimodal"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 1.0,
      "output": 2.0
    },
    "latencyClass": "fast",
    "status": "active"
  },
  "perplexity-sonar-deep-research": {
    "key": "perplexity-sonar-deep-research",
    "name": "Sonar Deep Research",
    "modelString": "sonar-deep-research",
    "providerKey": "perplexity",
    "description": "Asynchronous high-effort research model for intensive queries",
    "contextWindow": 128000,
    "outputWindow": 8000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "web-search", "citations", "multimodal", "deep-research", "async"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 5.0,
      "output": 10.0
    },
    "latencyClass": "slow",
    "status": "active",
    "features": ["adjustable-depth", "academic-research"]
  },
  "perplexity-r1-1776": {
    "key": "perplexity-r1-1776",
    "name": "R1-1776",
    "modelString": "r1-1776",
    "providerKey": "perplexity",
    "description": "Offline static model for privacy or air-gapped scenarios",
    "contextWindow": 128000,
    "outputWindow": 8000,
    "knowledgeCutoff": "2023",
    "capabilities": ["chat", "completion"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 1.0,
      "output": 2.0
    },
    "latencyClass": "fast",
    "status": "active",
    "limitations": ["no-web-search", "no-image-input", "offline-only"]
  },
  "vercel-v0-1.0-md": {
    "key": "vercel-v0-1.0-md",
    "name": "v0 1.0 MD",
    "modelString": "v0-1.0-md",
    "providerKey": "vercel",
    "description": "Legacy model optimized for web development with auto-fix and quick edits",
    "contextWindow": 128000,
    "outputWindow": 32000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "code-generation", "multimodal", "auto-fix", "composite-reasoning"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 1.5,
      "output": 2.5
    },
    "latencyClass": "fast",
    "status": "active",
    "features": ["next-js-optimized", "react-optimized"]
  },
  "vercel-v0-1.5-md": {
    "key": "vercel-v0-1.5-md",
    "name": "v0 1.5 MD",
    "modelString": "v0-1.5-md",
    "providerKey": "vercel",
    "description": "Everyday tasks and UI generation with improved composite architecture",
    "contextWindow": 128000,
    "outputWindow": 32000,
    "knowledgeCutoff": "2024-05",
    "isDefault": true,
    "capabilities": ["chat", "completion", "code-generation", "ui-generation", "multimodal", "composite-reasoning"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 1.5,
      "output": 2.5
    },
    "latencyClass": "fast",
    "status": "active"
  },
  "vercel-v0-1.5-lg": {
    "key": "vercel-v0-1.5-lg",
    "name": "v0 1.5 LG",
    "modelString": "v0-1.5-lg",
    "providerKey": "vercel",
    "description": "Advanced reasoning and large-scale edits with 512K context",
    "contextWindow": 512000,
    "outputWindow": 32000,
    "knowledgeCutoff": "2024-05",
    "capabilities": ["chat", "completion", "code-generation", "ui-generation", "multimodal", "advanced-thinking"],
    "supportedModes": ["streaming"],
    "costPer1kTokens": {
      "input": 7.5,
      "output": 37.5
    },
    "latencyClass": "standard",
    "status": "active",
    "warning": "Depletes API credits quickly"
  },
  "openrouter-openai-gpt-4.1": {
    "key": "openrouter-openai-gpt-4.1",
    "name": "GPT-4.1 (via OpenRouter)",
    "modelString": "openai/gpt-4.1",
    "providerKey": "openrouter",
    "description": "OpenAI GPT-4.1 accessed through OpenRouter",
    "contextWindow": 128000,
    "isDefault": true,
    "capabilities": ["chat", "completion", "tools", "json"],
    "supportedModes": ["streaming", "json", "tools"],
    "status": "active"
  },
  "openrouter-anthropic-claude-4-sonnet": {
    "key": "openrouter-anthropic-claude-4-sonnet",
    "name": "Claude 4 Sonnet (via OpenRouter)",
    "modelString": "anthropic/claude-4-sonnet",
    "providerKey": "openrouter",
    "description": "Anthropic Claude accessed through OpenRouter",
    "contextWindow": 200000,
    "capabilities": ["chat", "completion", "tools", "json"],
    "supportedModes": ["streaming", "json", "tools"],
    "status": "active"
  },
  "openrouter-meta-llama-3.1-405b": {
    "key": "openrouter-meta-llama-3.1-405b",
    "name": "Llama 3.1 405B (via OpenRouter)",
    "modelString": "meta-llama/llama-3.1-405b-instruct",
    "providerKey": "openrouter",
    "description": "Meta's largest Llama model",
    "contextWindow": 131072,
    "capabilities": ["chat", "completion"],
    "supportedModes": ["streaming", "json"],
    "status": "active"
  }
}